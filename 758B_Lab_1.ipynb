{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "758B-Lab-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyML/j2cDO1d+XFRghv/dKqL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JYu89828/Airbnb-Kaggle-Challenge/blob/master/758B_Lab_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_a8sWJvWjG2",
        "outputId": "7d130ca4-b6ad-439b-d3f6-5282739a00a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "fname='facebook_comments.csv'\n",
        "\n",
        "df_train=pd.read_csv(fname,header=None,names=['text','sentiment'],encoding='iso-8859-1', lineterminator='\\n')\n",
        "\n",
        "sent={'positive':2,'neutral':1,'negative':0}\n",
        "df_train['labels']=df_train['sentiment'].str.strip().map(sent)\n",
        "\n",
        "training_texts=df_train.text.values\n",
        "labels=df_train.labels.values\n",
        "\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Heres a single  to add  to Kindle. Just read t...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>If you tire of Non-Fiction.. Check out http://...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ghost of Round Island is supposedly nonfiction.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why is Barnes and Nobles version of the Kindle...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@Maria:  Do you mean the Nook?  Be careful  bo...</td>\n",
              "      <td>positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  sentiment  labels\n",
              "0  Heres a single  to add  to Kindle. Just read t...    neutral       1\n",
              "1  If you tire of Non-Fiction.. Check out http://...    neutral       1\n",
              "2   Ghost of Round Island is supposedly nonfiction.     neutral       1\n",
              "3  Why is Barnes and Nobles version of the Kindle...   negative       0\n",
              "4  @Maria:  Do you mean the Nook?  Be careful  bo...   positive       2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 299
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3sFSWpYWTSf",
        "outputId": "deffaee2-fd6d-4b17-f072-d70da26cc558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXiqlJg9WUNO"
      },
      "source": [
        "# Preprocess dat\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIBAtPtzZNFX",
        "outputId": "395a0177-d450-4b7d-ce9d-610a30fcbe55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer=TfidfVectorizer(stop_words='english',max_features=500, ngram_range=(1,2))\n",
        "\n",
        "instances=vectorizer.fit_transform(training_texts)\n",
        "\n",
        "X=instances\n",
        "Y=labels\n",
        "\n",
        "print(X.shape,',',Y.shape)\n"
      ],
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 500) , (1999,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ11NoZnonFe"
      },
      "source": [
        "# Traditional Random Forest Approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoScmGJsavdn",
        "outputId": "a907f6ec-8921-4217-fb9c-ef0319690cee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "kfold=KFold(n_splits=10,shuffle=True,random_state=2020)\n",
        "rf_model=RandomForestClassifier(criterion='entropy',max_depth=2, random_state=2020)\n",
        "rf_cvscores=[]\n",
        "\n",
        "for train_idx, test_idx in kfold.split(X):\n",
        "  rf_model.fit(X[train_idx],Y[train_idx])\n",
        "  acc=rf_model.score(X[test_idx],Y[test_idx])\n",
        "  rf_cvscores.append(acc)\n",
        "\n",
        "print('Random Forest - mean: %.4f%%(std:+/- %.4f%%)' % (np.mean(rf_cvscores)*100,np.std(rf_cvscores)*100))"
      ],
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest - mean: 64.1332%(std:+/- 2.0919%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8BJaHKiofdG"
      },
      "source": [
        "# Fully connected feedforward Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6KLcHNZc6IQ"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n"
      ],
      "execution_count": 303,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUozOpPLpKol"
      },
      "source": [
        "Build the train loader and validation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6_Sqmn4c6S-"
      },
      "source": [
        "epochs=5\n",
        "lr=1e-4\n",
        "indim=X.shape[1]\n",
        "outdim=3\n",
        "drate=0.7\n",
        "batch_size=16\n",
        "\n",
        "X_tensor=torch.from_numpy(X.toarray())\n",
        "Y_tensor=torch.from_numpy(Y)\n",
        "\n",
        "dataset=TensorDataset(X_tensor,Y_tensor)\n",
        "train_size=int(0.8*len(dataset))\n",
        "val_size=len(dataset)-train_size\n",
        "train_dataset, val_dataset=torch.utils.data.random_split(dataset,[train_size,val_size])\n",
        "\n",
        "train_loader=DataLoader(train_dataset,batch_size,shuffle=True)\n",
        "\n",
        "val_loader=DataLoader(val_dataset, batch_size,shuffle=True)"
      ],
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVkSgHYAdzpo",
        "outputId": "0f3b9cb0-5046-47b1-b5dc-4423b0c3b07d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "class SentimentNetwork(nn.Module):\n",
        "  def __init__(self,input_dim,output_dim,dropout_rate):\n",
        "    super(SentimentNetwork,self).__init__()\n",
        "    self.fc1=nn.Linear(input_dim,100)\n",
        "    self.do1=nn.Dropout(dropout_rate)\n",
        "    self.fc2=nn.Linear(100,50)\n",
        "    self.fc3=nn.Linear(50,output_dim)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=F.relu(self.fc1(x))\n",
        "    x=self.do1(x)\n",
        "    x=F.relu(self.fc2(x))\n",
        "    x=F.log_softmax(self.fc3(x))\n",
        "\n",
        "    return x\n",
        "\n",
        "  \n",
        "model=SentimentNetwork(indim,outdim,drate)\n",
        "print(model)"
      ],
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentNetwork(\n",
            "  (fc1): Linear(in_features=500, out_features=100, bias=True)\n",
            "  (do1): Dropout(p=0.7, inplace=False)\n",
            "  (fc2): Linear(in_features=100, out_features=50, bias=True)\n",
            "  (fc3): Linear(in_features=50, out_features=3, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJTh4L83pXz_"
      },
      "source": [
        "Create a training function to train the model and an evaluation function to evaluate the performance on the separate validation set \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSqyvv1BYiT5"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion =  torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 306,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNReKFMzk4BT"
      },
      "source": [
        "def train(model,train_loader,optimizer, criterion):\n",
        "  epoch_loss, epoch_acc=0.0,0.0\n",
        "  model.train()\n",
        "  for batch_x, batch_y in enumerate(train_loader):\n",
        "    inputs, labels = batch_y\n",
        "\n",
        "\n",
        "    optimizer.zero_grad() \n",
        "    model_out = model(inputs.float()) \n",
        "\n",
        "    loss = criterion(model_out, labels)\n",
        "    acc=model_out.data.max(dim=1)[1].eq(labels.data).sum()\n",
        "    loss.backward()\n",
        "    optimizer.step() \n",
        "\n",
        "    epoch_loss+=loss.item()\n",
        "    epoch_acc+=acc\n",
        "  epoch_loss/=len(train_loader)\n",
        "\n",
        "\n",
        "  return epoch_loss, epoch_acc\n",
        "    "
      ],
      "execution_count": 318,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI6jrdBRCXtx"
      },
      "source": [
        "def evaluate(model, val_loader, criterion):\n",
        "  epoch_loss, epoch_acc=0.0,0.0\n",
        "  model.eval()\n",
        "  for batch_x, batch_y in enumerate(val_loader):\n",
        "    inputs, labels = batch_y\n",
        "    \n",
        "\n",
        "    optimizer.zero_grad() \n",
        "    model_out = model(inputs.float()) \n",
        "\n",
        "    loss = criterion(model_out, labels)\n",
        "    acc=model_out.data.max(dim=1)[1].eq(labels.data).sum()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step() \n",
        "\n",
        "    epoch_loss+=loss.item()\n",
        "    epoch_acc+=acc\n",
        "  epoch_loss/=len(val_loader)\n",
        "\n",
        "\n",
        "\n",
        "  return epoch_loss, epoch_acc\n",
        "    \n"
      ],
      "execution_count": 319,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDy14brXpnEf"
      },
      "source": [
        "Main starting point: train the model and evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpzHFa34nokx",
        "outputId": "cbf89d19-4262-45ae-93b2-ec43ad1b2b24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
        "  valid_loss, valid_acc = evaluate(model, val_loader, criterion)\n",
        "    \n",
        "  print(f'Epoch: {epoch+1:02}')\n",
        "  print(f'\\tTrain Loss: {train_loss:.4f} | Train Acc: {train_acc/len(train_loader.dataset):.4f}')\n",
        "  print(f'\\t Val. Loss: {valid_loss:.4f} |  Val. Acc: {valid_acc/len(val_loader.dataset):.4f}')"
      ],
      "execution_count": 320,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01\n",
            "\tTrain Loss: 0.8306 | Train Acc: 0.6479\n",
            "\t Val. Loss: 0.8438 |  Val. Acc: 0.6150\n",
            "Epoch: 02\n",
            "\tTrain Loss: 0.8300 | Train Acc: 0.6479\n",
            "\t Val. Loss: 0.8427 |  Val. Acc: 0.6150\n",
            "Epoch: 03\n",
            "\tTrain Loss: 0.8290 | Train Acc: 0.6479\n",
            "\t Val. Loss: 0.8412 |  Val. Acc: 0.6150\n",
            "Epoch: 04\n",
            "\tTrain Loss: 0.8300 | Train Acc: 0.6479\n",
            "\t Val. Loss: 0.8394 |  Val. Acc: 0.6150\n",
            "Epoch: 05\n",
            "\tTrain Loss: 0.8254 | Train Acc: 0.6479\n",
            "\t Val. Loss: 0.8380 |  Val. Acc: 0.6150\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}